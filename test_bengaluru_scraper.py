#!/usr/bin/env python3
"""
Quick test script for Bengaluru Project Scraper
"""

import sys
import os
import json
from datetime import datetime

# Add the python_scripts directory to the path
sys.path.append('python_scripts')

try:
    from bengaluru_project_scraper import BengaluruProjectScraper
    
    def test_scraper():
        print("ğŸ§ª Testing Bengaluru Project Scraper...")
        print("=" * 50)
        
        # Initialize scraper
        scraper = BengaluruProjectScraper()
        
        try:
            # Test keyword detection
            print("ğŸ” Testing keyword detection...")
            test_texts = [
                "BBMP road development in Bengaluru",
                "BDA housing scheme in Bangalore",
                "Metro construction in Karnataka",
                "Water supply project in Mumbai",  # Should be filtered out
                "BWSSB infrastructure in Bengaluru"
            ]
            
            for text in test_texts:
                is_related = scraper.is_bengaluru_related(text)
                status = "âœ…" if is_related else "âŒ"
                print(f"  {status} '{text}' -> {is_related}")
            
            print("\nğŸ—ï¸ Testing project extraction...")
            
            # Test a few portals (limited to avoid long execution)
            print("  ğŸ“Š Testing BBMP portal...")
            scraper.scrape_bbmp_portal()
            
            print("  ğŸ  Testing BDA portal...")
            scraper.scrape_bda_portal()
            
            print("  ğŸ’§ Testing BWSSB portal...")
            scraper.scrape_bwssb_portal()
            
            # Show results
            projects = scraper.projects
            print(f"\nğŸ“ˆ Results:")
            print(f"  Total projects found: {len(projects)}")
            
            if projects:
                # Group by source
                sources = {}
                for project in projects:
                    source = project.get('source', 'Unknown')
                    sources[source] = sources.get(source, 0) + 1
                
                print(f"\nğŸ“Š Projects by source:")
                for source, count in sources.items():
                    print(f"  {source}: {count}")
                
                # Show sample project
                print(f"\nğŸ“‹ Sample project:")
                sample = projects[0]
                print(f"  Name: {sample.get('projectName', 'N/A')}")
                print(f"  Source: {sample.get('source', 'N/A')}")
                print(f"  Budget: â‚¹{sample.get('budget', 0):,}")
                print(f"  Status: {sample.get('status', 'N/A')}")
                print(f"  Location: {sample.get('location', 'N/A')}")
            
            # Save test results
            if projects:
                scraper.save_to_json(projects, 'test_bengaluru_projects.json')
                print(f"\nğŸ’¾ Test results saved to test_bengaluru_projects.json")
            
            print(f"\nâœ… Test completed successfully!")
            
        except Exception as e:
            print(f"âŒ Test failed: {e}")
            import traceback
            traceback.print_exc()
        
        finally:
            scraper.close()
    
    if __name__ == "__main__":
        test_scraper()
        
except ImportError as e:
    print(f"âŒ Import error: {e}")
    print("ğŸ’¡ Make sure you're running from the project root directory")
    print("ğŸ’¡ Install required packages: pip install requests beautifulsoup4 selenium webdriver-manager lxml pandas")
